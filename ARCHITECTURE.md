# ORION Infrastructure Architecture

**Dell PowerEdge R730 - Proxmox VE Multi-Layer Infrastructure**

Version: 2.0 (Post-Refactoring)
Last Updated: 2025-11-22

---

## üéØ Overview

ORION is a complete infrastructure stack built on a Dell R730 Proxmox VE hypervisor, designed from the ground up as an **AI-first, agent-driven architecture** with security hardening through technological obscurity ("AI Maze").

### Design Philosophy

1. **Proper Domain Separation**: Clear boundaries between Infrastructure, Platform, Applications, AI/Agent, IPAM, and Observability layers
2. **Infrastructure as Code**: Terraform for declarative VM deployment, Ansible for configuration
3. **Hybrid Approach**: VMs for infrastructure, LXC for AI/ML, Kubernetes for applications
4. **AI-First**: Built around multi-agent orchestration with proper inference layer
5. **Security Through Obscurity**: Non-standard tech stack (Swift/Vapor, Backstage) to confuse automated scanners

---

## üèóÔ∏è Architecture Layers

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Dell R730 Proxmox VE Host                     ‚îÇ
‚îÇ              (56 cores, 384GB RAM, dual 10GbE, iDRAC9)               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Layer 0: Infrastructure VMs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  VM 200: Router (BIRD2 BGP, IPv6, Firewall) - 8C/32GB        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  VM 300: AI Coordinator (Multi-agent orchestration) - 4C/16GB‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  VM 500: NetBox (IPAM, network docs) - 4C/8GB                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  VM 600-603: K3s Cluster (1 master, 3 workers) - 4C/8-16GB   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Layer 1: LXC Containers (AI/ML) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  LXC 1000: Ollama (llama3, codellama, mistral)               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  LXC 1001: OpenWebUI (ChatGPT-like interface)                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  LXC 1002: LiteLLM (API gateway, OpenAI compatible)           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  LXC 1003: FlowiseAI (Visual agent workflow builder)          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  LXC 1004: PostgreSQL + pgvector (Vector DB for RAG)         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  LXC 1005: Redis (Caching, rate limiting)                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  LXC 1006: Minio (S3-compatible storage)                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  LXC 1007: Nginx Proxy Manager (Reverse proxy with SSL)      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  LXC 1008: Wireguard (VPN for secure remote access)          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  LXC 1009: N8N (Workflow automation)                         ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Layer 2: Kubernetes Workloads (K3s) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                                                                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Infrastructure:                                               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ kube-prometheus-stack (Prometheus, Grafana, AlertManager) ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Cilium (CNI, network policy, eBPF)                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ Longhorn (Distributed block storage)                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Applications:                                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Backstage (Developer portal - "AI Maze" frontend)         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ Vapor API (Swift middleware layer)                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  AI Agents:                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Infrastructure Agent (resource management)                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Network Agent (BGP, routing, firewall)                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Security Agent (threat detection, hardening)              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ DevOps Agent (CI/CD, deployments)                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîå Network Architecture

### Physical Interfaces

```
Dell R730:
‚îú‚îÄ eno1 (10GbE) ‚Üí vmbr0 (WAN - Telus Fiber)
‚îú‚îÄ eno2 (10GbE) ‚Üí vmbr1 (LAN - 192.168.100.0/24)
‚îú‚îÄ eno3 (1GbE)  ‚Üí vmbr2 (Guest - 192.168.200.0/24)
‚îî‚îÄ iDRAC (IPMI) ‚Üí 192.168.1.100/24
```

### IP Allocation

| Network Segment | CIDR | Purpose |
|----------------|------|---------|
| WAN | DHCP from Telus | Internet uplink |
| LAN | 192.168.100.0/24 | Internal services |
| Guest | 192.168.200.0/24 | Isolated guest network |
| Management | 192.168.1.0/24 | iDRAC and management |

### IPv6 BGP Routing

**AS Number**: 394955
**IPv6 Prefix**: 2602:F674::/48
**Peer**: AS6939 (Telus)

```
Subnet Allocation (2602:F674::/48):
‚îú‚îÄ 2602:F674:0000::/64 ‚Üí WAN/Transit
‚îú‚îÄ 2602:F674:1000::/64 ‚Üí LAN
‚îú‚îÄ 2602:F674:2000::/64 ‚Üí Guest
‚îú‚îÄ 2602:F674:3000::/64 ‚Üí Management
‚îú‚îÄ 2602:F674:4000::/64 ‚Üí K8s Pods
‚îî‚îÄ 2602:F674:5000::/64 ‚Üí K8s Services
```

**BGP Implementation**: BIRD2 (Phase 1) ‚Üí GoBGP (Phase 2 migration)

---

## ü§ñ AI/Agent Architecture (4-Layer Stack)

### Layer 0: Inference (Ollama - LXC 1000)

**Purpose**: Local LLM inference engine

- **Models**: llama3, codellama, mistral, neural-chat
- **API**: OpenAI-compatible REST API
- **Hardware**: Direct hardware access for GPU (if available)
- **Deployment**: LXC container via helper script

### Layer 1: Orchestration (LiteLLM - LXC 1002)

**Purpose**: Unified API gateway for multiple LLM backends

- **Features**:
  - OpenAI-compatible API
  - Multi-model routing
  - Rate limiting (Redis integration)
  - Caching
  - Load balancing
- **Backends**: Ollama (local), OpenAI (fallback), Anthropic (fallback)

### Layer 2: Agent Framework (K8s Pods)

**Specialized Agents**:

1. **Infrastructure Agent**
   - Resource monitoring (CPU, RAM, disk, network)
   - VM lifecycle management
   - Storage provisioning
   - Capacity planning

2. **Network Agent**
   - BGP session monitoring
   - Route optimization
   - Firewall rule management
   - Traffic analysis

3. **Security Agent**
   - Threat detection
   - Vulnerability scanning
   - Hardening recommendations
   - Compliance checking

4. **DevOps Agent**
   - CI/CD pipeline management
   - Deployment automation
   - Rollback strategies
   - Log analysis

### Layer 3: Coordinator (AI Coordinator - VM 300)

**Purpose**: Multi-agent orchestration and decision-making

- **Framework**: LangGraph for workflow orchestration
- **Capabilities**:
  - Inter-agent communication
  - Task delegation
  - Conflict resolution
  - State management
  - Human-in-the-loop approvals

---

## üîê "AI Maze" Security Architecture

### Concept

Use uncommon technology stack to confuse automated vulnerability scanners and bots:

1. **Backstage (Developer Portal)** - Not commonly scanned by bots
2. **Vapor (Swift Web Framework)** - Extremely rare in infrastructure
3. **Unusual Port Assignments** - Non-standard ports for services
4. **Request Routing Obfuscation** - Multi-layer proxying

### Flow

```
Internet ‚Üí Nginx Proxy Manager ‚Üí Backstage (Node.js)
                                       ‚Üì
                                 Vapor API (Swift)
                                       ‚Üì
                            Internal Services (Go, Python, Rust)
```

**Scanner Perspective**:
- Sees Backstage (JavaScript/TypeScript) - expects Node.js backend
- Actually hits Vapor (Swift) - no known exploits, confuses scanners
- By the time scanner adapts, requests are rate-limited/blocked

---

## üì¶ Deployment Strategy

### Why LXC for AI/ML?

| Aspect | LXC Containers | K8s Pods | VMs |
|--------|---------------|----------|-----|
| **Deployment Time** | 5 minutes | Hours | Hours |
| **Resource Overhead** | Low | Medium | High |
| **GPU Access** | Direct | Complex | Passthrough |
| **Storage** | Persistent | Volumes | Easy |
| **Management** | Proxmox UI | kubectl | Proxmox UI |
| **Maintenance** | Community | Self | Self |

**Decision**: Use LXC containers (via tteck's helper scripts) for AI/ML stack

### Deployment Phases

#### Phase 1: Infrastructure VMs (Terraform)

```bash
make apply
```

Deploys:
- VM 200: Router
- VM 300: AI Coordinator
- VM 500: NetBox
- VM 600-603: K3s cluster

#### Phase 2: AI/ML Stack (LXC Helper Scripts)

```bash
make deploy-ai-stack
```

Provides commands to run on Proxmox host:
- LXC 1000: Ollama
- LXC 1001: OpenWebUI
- LXC 1002: LiteLLM
- LXC 1003: FlowiseAI
- LXC 1004: PostgreSQL + pgvector
- LXC 1005: Redis

#### Phase 3: Infrastructure Services (LXC)

```bash
make deploy-infrastructure
```

Deploys:
- LXC 1006: Minio
- LXC 1007: Nginx Proxy Manager
- LXC 1008: Wireguard

#### Phase 4: VM Configuration (Ansible)

```bash
make configure
```

Configures:
- Router: BIRD2, firewall, routing
- NetBox: IPAM setup
- K3s: Cluster initialization

#### Phase 5: K8s Workloads

```bash
make k8s-deploy
```

Deploys:
- Infrastructure: Prometheus, Grafana, Cilium, Longhorn
- Applications: Backstage, Vapor API
- AI Agents: All 4 specialized agents

### Complete Deployment

```bash
make deploy-full
```

Runs all phases sequentially.

---

## üìÅ Repository Structure

```
luci-macOSX-PROXMOX/
‚îú‚îÄ‚îÄ terraform/               # Infrastructure as Code
‚îÇ   ‚îú‚îÄ‚îÄ main.tf             # VM definitions
‚îÇ   ‚îú‚îÄ‚îÄ variables.tf        # Variable definitions
‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf          # Output values
‚îÇ   ‚îú‚îÄ‚îÄ providers.tf        # Proxmox provider config
‚îÇ   ‚îî‚îÄ‚îÄ terraform.tfvars    # Actual values (gitignored)
‚îÇ
‚îú‚îÄ‚îÄ ansible/                # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ inventory/          # Host inventory
‚îÇ   ‚îú‚îÄ‚îÄ playbooks/          # Playbooks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ site.yml       # Main playbook
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ router.yml     # Router config
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ netbox.yml     # NetBox setup
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ k8s.yml        # K8s cluster
‚îÇ   ‚îú‚îÄ‚îÄ group_vars/         # Group variables
‚îÇ   ‚îú‚îÄ‚îÄ host_vars/          # Host-specific variables
‚îÇ   ‚îî‚îÄ‚îÄ roles/              # Ansible roles
‚îÇ       ‚îú‚îÄ‚îÄ common/         # Common setup
‚îÇ       ‚îú‚îÄ‚îÄ bird2/          # BIRD2 BGP
‚îÇ       ‚îú‚îÄ‚îÄ gobgp/          # GoBGP (Phase 2)
‚îÇ       ‚îú‚îÄ‚îÄ k3s-master/     # K3s master
‚îÇ       ‚îú‚îÄ‚îÄ k3s-worker/     # K3s worker
‚îÇ       ‚îú‚îÄ‚îÄ netbox/         # NetBox
‚îÇ       ‚îî‚îÄ‚îÄ ai-coordinator/ # AI coordinator
‚îÇ
‚îú‚îÄ‚îÄ kubernetes/             # K8s manifests
‚îÇ   ‚îú‚îÄ‚îÄ infrastructure/     # Core services
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kube-prometheus-stack/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cilium/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ longhorn/
‚îÇ   ‚îú‚îÄ‚îÄ applications/       # Apps
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backstage/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vapor-api/
‚îÇ   ‚îî‚îÄ‚îÄ ai-agents/          # AI agents
‚îÇ       ‚îú‚îÄ‚îÄ ollama/         # Ollama client
‚îÇ       ‚îú‚îÄ‚îÄ litellm/        # LiteLLM client
‚îÇ       ‚îî‚îÄ‚îÄ agents/
‚îÇ           ‚îú‚îÄ‚îÄ infrastructure/
‚îÇ           ‚îú‚îÄ‚îÄ network/
‚îÇ           ‚îú‚îÄ‚îÄ security/
‚îÇ           ‚îî‚îÄ‚îÄ devops/
‚îÇ
‚îú‚îÄ‚îÄ router-configs/         # Router configurations
‚îÇ   ‚îú‚îÄ‚îÄ bird2/             # BIRD2 configs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bird.conf      # IPv4
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ bird6.conf     # IPv6
‚îÇ   ‚îî‚îÄ‚îÄ gobgp/             # GoBGP configs (Phase 2)
‚îÇ
‚îú‚îÄ‚îÄ docs/                   # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ deployment-guide/  # Deployment docs
‚îÇ   ‚îú‚îÄ‚îÄ ai-agent-design/   # AI agent architecture
‚îÇ   ‚îú‚îÄ‚îÄ network-design/    # Network diagrams
‚îÇ   ‚îî‚îÄ‚îÄ reference/         # Old docs (archived)
‚îÇ
‚îú‚îÄ‚îÄ Makefile               # One-command deployment
‚îú‚îÄ‚îÄ ARCHITECTURE.md        # This file
‚îú‚îÄ‚îÄ ARCHITECTURE_REVIEW.md # AI engineering review
‚îú‚îÄ‚îÄ README.md              # Project overview
‚îî‚îÄ‚îÄ .gitignore
```

---

## üöÄ Quick Start

### Prerequisites

1. **Dell R730** with Proxmox VE 8.x installed
2. **Terraform** >= 1.6.0
3. **Ansible** >= 2.15
4. **kubectl** (for K8s management)
5. **Proxmox API Token** created

### Deployment

```bash
# 1. Clone repository
git clone https://github.com/luci-digital/luci-macOSX-PROXMOX.git
cd luci-macOSX-PROXMOX

# 2. Configure Terraform
cp terraform/terraform.tfvars.example terraform/terraform.tfvars
nano terraform/terraform.tfvars  # Add your Proxmox API token

# 3. Deploy everything
make deploy-full

# 4. Verify
make verify
make outputs
```

### Individual Deployments

```bash
# Deploy VMs only
make apply

# Deploy AI/ML stack only
make deploy-ai-stack

# Deploy infrastructure services only
make deploy-infrastructure

# Deploy K8s workloads only
make k8s-deploy
```

---

## üìä Resource Allocation

| Component | CPU Cores | Memory | Disk | Network |
|-----------|-----------|--------|------|---------|
| **Router** | 8 | 32GB | 50GB | 4x virtio |
| **AI Coordinator** | 4 | 16GB | 100GB | 1x virtio |
| **NetBox** | 4 | 8GB | 100GB | 1x virtio |
| **K3s Master** | 4 | 8GB | 100GB | 1x virtio |
| **K3s Workers (√ó3)** | 4 each | 16GB each | 100GB each | 1x virtio |
| **LXC Containers** | Variable | Variable | Variable | Bridge |
| **Total Used** | ~40 cores | ~120GB | ~750GB | - |
| **Available** | 16 cores | 264GB | - | - |

---

## üîÑ Migration Paths

### BIRD2 ‚Üí GoBGP (Phase 2)

**Why Migrate?**
- API-driven configuration (vs. config files)
- Better integration with K8s
- Programmable routing policies
- Real-time monitoring via gRPC

**Timeline**: After Phase 1 stabilization (3-6 months)

**Migration Steps**:
1. Deploy GoBGP alongside BIRD2
2. Configure GoBGP with same peering
3. Test in parallel
4. Gracefully shutdown BIRD2 sessions
5. Cutover to GoBGP
6. Monitor for 48 hours
7. Remove BIRD2

### Future Enhancements

- **GPU Passthrough**: Add NVIDIA GPU for faster LLM inference
- **HA Setup**: Proxmox cluster with second R730
- **Object Storage**: Expand Minio for backups and AI model storage
- **Monitoring**: Enhanced metrics with VictoriaMetrics
- **GitOps**: Implement ArgoCD for K8s deployments

---

## üìö Documentation

- **[Deployment Guide](docs/deployment-guide/)** - Step-by-step instructions
- **[AI Agent Design](docs/ai-agent-design/)** - Agent architecture details
- **[Network Design](docs/network-design/)** - Network topology and routing
- **[Helper Scripts Integration](docs/HELPER_SCRIPTS_INTEGRATION.md)** - LXC deployment guide
- **[IPv6 Routing](docs/IPV6_ROUTING_INTEGRATION.md)** - BGP configuration
- **[Architecture Review](ARCHITECTURE_REVIEW.md)** - AI engineering analysis

---

## üîß Operations

### Monitoring

- **Proxmox Web UI**: https://192.168.1.100:8006
- **NetBox**: http://192.168.100.50:8000
- **Grafana**: http://192.168.100.60:30080 (K8s NodePort)
- **OpenWebUI**: http://192.168.100.30:3000 (LXC 1001)
- **Backstage**: http://192.168.100.60:30000 (K8s NodePort)

### Troubleshooting

```bash
# Check Terraform state
make status

# View all outputs
make outputs

# Verify connectivity
make verify

# View Terraform plan
make plan

# SSH to VMs
ssh root@192.168.100.1   # Router
ssh root@192.168.100.30  # AI Coordinator
ssh root@192.168.100.50  # NetBox
ssh root@192.168.100.60  # K3s Master
```

---

## üéØ Design Decisions

### Why This Architecture?

1. **VMs for Infrastructure**: Stable, proven, easy to manage
2. **LXC for AI/ML**: Lightweight, fast deployment, community-maintained scripts
3. **K8s for Applications**: Modern orchestration, perfect for stateless apps
4. **Hybrid Approach**: Right tool for the right job

### What We Eliminated

- ‚ùå All-in-one deployment scripts (replaced with Terraform + Makefile)
- ‚ùå VMs 400/401 (Backstage/Vapor moved to K8s)
- ‚ùå Conflicting deployment paths (single path now)
- ‚ùå Ambiguous documentation (consolidated)

### What We Kept

- ‚úÖ Terraform for VMs (declarative, reproducible)
- ‚úÖ Ansible for configuration (proven, flexible)
- ‚úÖ BIRD2 for routing (stable, will migrate to GoBGP later)
- ‚úÖ K3s for K8s (lightweight, perfect for single-node)
- ‚úÖ AI-first design (multi-agent architecture)

---

## üîê Security Considerations

1. **Firewall**: nftables on router VM
2. **VPN**: Wireguard for remote access
3. **SSL/TLS**: Nginx Proxy Manager with Let's Encrypt
4. **Network Segmentation**: VLANs for LAN/Guest/Management
5. **API Security**: Rate limiting via LiteLLM + Redis
6. **Obscurity**: Uncommon tech stack (Vapor/Backstage)

---

## üìù Notes

- This architecture is post-refactoring (v2.0)
- All obsolete deployment scripts removed
- Single deployment path via Makefile
- Proper domain separation established
- AI/agent architecture clearly defined
- Helper scripts integration discovered and documented

---

**Last Updated**: 2025-11-22
**Status**: Active Development
**Next Milestone**: Complete Ansible playbooks for VM configuration
